# AI Interview Coach

An AI-powered interview practice platform that provides real-time feedback on body language, speech, and answer quality using computer vision and AI.

## ğŸ¯ Features

- **Real-Time Body Language Analysis**
  - Eye contact tracking
  - Posture detection
  - Fidgeting and gesture analysis

- **Speech Analysis**
  - Automatic transcription using OpenAI Whisper
  - Filler word detection ("um", "uh", "like")
  - Speaking pace analysis

- **AI-Powered Feedback**
  - Answer quality evaluation using Claude AI
  - STAR format detection
  - Personalized improvement suggestions

- **Progress Tracking**
  - Dashboard with performance metrics
  - Improvement trends over time
  - Session history and reports

## ğŸ—ï¸ Tech Stack

### Backend
- **FastAPI** - Modern Python web framework
- **SQLAlchemy** - Database ORM
- **MediaPipe** - Face and pose detection
- **OpenAI Whisper** - Speech-to-text
- **Anthropic Claude** - AI evaluation
- **SQLite** - Database (PostgreSQL for production)

### Frontend
- **React 18** - UI library
- **Vite** - Build tool
- **TailwindCSS** - Styling
- **React Query** - Data fetching
- **React Router** - Navigation
- **MediaPipe (Browser)** - Client-side face detection

## ğŸ“ Project Structure

```
ai-interview-coach/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/routes/          # API endpoints
â”‚   â”‚   â”œâ”€â”€ analyzers/           # Analysis logic
â”‚   â”‚   â”œâ”€â”€ database/            # Models and DB config
â”‚   â”‚   â””â”€â”€ utils/               # Helper functions
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/          # React components
â”‚   â”‚   â”œâ”€â”€ pages/               # Page components
â”‚   â”‚   â””â”€â”€ services/            # API services
â”‚   â””â”€â”€ package.json
â””â”€â”€ data/
    â”œâ”€â”€ videos/                  # Interview recordings
    â””â”€â”€ reports/                 # Generated reports
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.11+
- Node.js 18+
- npm or yarn

### Backend Setup

1. Navigate to backend directory:
```bash
cd backend
```

2. Create virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Create .env file:
```bash
cp .env.example .env
```

5. Add your Anthropic API key to .env:
```
ANTHROPIC_API_KEY=your_api_key_here
```

6. Run the server:
```bash
cd app
python -m uvicorn main:app --reload
```

Backend will be available at `http://localhost:8000`

### Frontend Setup

1. Navigate to frontend directory:
```bash
cd frontend
```

2. Install dependencies:
```bash
npm install
```

3. Start development server:
```bash
npm run dev
```

Frontend will be available at `http://localhost:5173`

## ğŸ“… Development Roadmap

### Sprint 1: Foundation (Days 1-5) âœ… DONE
- [x] Project structure
- [x] Backend API setup
- [x] Frontend React setup
- [x] Database models
- [ ] Video recording
- [ ] Face detection integration

### Sprint 2: Analysis (Days 6-10)
- [ ] Eye contact tracking
- [ ] Posture analysis
- [ ] Speech-to-text integration
- [ ] Filler word detection
- [ ] Claude AI integration

### Sprint 3: Reports (Days 11-15)
- [ ] Report generation
- [ ] Dashboard with charts
- [ ] PDF export
- [ ] Progress tracking

### Sprint 4: Deployment (Days 16-20)
- [ ] Docker setup
- [ ] Deploy backend
- [ ] Deploy frontend
- [ ] Documentation
- [ ] Demo video

## ğŸ”‘ Getting Anthropic API Key

1. Go to https://console.anthropic.com/
2. Sign up (get $5 free credit)
3. Navigate to "API Keys"
4. Create new key
5. Add to `.env` file

## ğŸ“Š Database Schema

### InterviewSession
- Stores overall interview data
- Tracks scores and metrics
- Links to video recordings

### Question
- Interview question bank
- Categorized by type and difficulty

### InterviewAnswer
- Individual answers within sessions
- Detailed metrics per answer

### UserProgress
- Long-term progress tracking
- Improvement metrics

## ğŸ§ª Testing the API

Once backend is running, visit:
- API Docs: http://localhost:8000/docs
- Health Check: http://localhost:8000/api/health

## ğŸ“ API Endpoints

### Interviews
- `POST /api/interviews/start` - Start new session
- `GET /api/interviews/{id}` - Get session details
- `GET /api/interviews/` - List all sessions
- `POST /api/interviews/{id}/upload-video` - Upload video
- `POST /api/interviews/{id}/complete` - Complete session

### Analysis
- `POST /api/analysis/analyze` - Analyze session
- `GET /api/analysis/real-time/{id}` - Real-time metrics

### Reports
- `GET /api/reports/{id}` - Get detailed report
- `GET /api/reports/{id}/pdf` - Download PDF
- `GET /api/reports/progress/summary` - Progress summary

## ğŸ¨ UI Screenshots

(Will be added as development progresses)

## ğŸ¤ Contributing

This is a personal portfolio project, but suggestions are welcome!

## ğŸ“„ License

MIT License - feel free to use for your own learning

## ğŸ‘¤ Author

Your Name
- Portfolio: (link)
- LinkedIn: (link)
- GitHub: (link)

## ğŸ™ Acknowledgments

- MediaPipe by Google
- Anthropic Claude API
- OpenAI Whisper
- FastAPI community

---

**Status**: ğŸš§ In Development (Day 1/20 Complete)
**Next**: Implement video recording and face detection
